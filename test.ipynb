{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473f55dd",
   "metadata": {},
   "source": [
    "# Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd557b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_spaces(spaced_string):\n",
    "    previous_spased = [i for i,ch in enumerate(spaced_string) if ch == \" \"]\n",
    "    for idx in range(len(previous_spased)):\n",
    "        previous_spased[idx] -= idx\n",
    "\n",
    "    return previous_spased\n",
    "\n",
    "\n",
    "def f1_metrics(pred_spaces, target_spaces):\n",
    "    tp = fp = fn = 0\n",
    "    \n",
    "    for p,g in zip(pred_spaces, target_spaces):\n",
    "        pset = set(define_spaces(p))\n",
    "        gset = set(define_spaces(g))\n",
    "        tp += len(pset & gset)\n",
    "        fp += len(pset - gset)\n",
    "        fn += len(gset - pset)\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2*prec*rec/(prec+rec) if (prec+rec) > 0 else 0.0\n",
    "    \n",
    "    return {\"precision\": prec, \"recall\": rec, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f90e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_spaces(text, model, tokenizer, device=device, max_len = 40):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_len)\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "        gen_ids = model.generate(\n",
    "            input_ids=enc[\"input_ids\"],\n",
    "            attention_mask=enc.get(\"attention_mask\", None),\n",
    "            max_length=max_len,\n",
    "            num_beams=1,\n",
    "            no_repeat_ngram_size=0\n",
    "        )\n",
    "\n",
    "        gen_ids = gen_ids.cpu()\n",
    "        decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "        predict = decoded[0] if len(decoded) > 0 else \"\"\n",
    "        spaced_predict = define_spaces(predict)\n",
    "\n",
    "        return predict, spaced_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"best_model\"\n",
    "\n",
    "tokenizer_saved = T5Tokenizer.from_pretrained(model_path)\n",
    "model_saved = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "model_saved.to(device)\n",
    "\n",
    "test_str = \"этотестовая777строкадляproverkiрезультата\"\n",
    "test_str_spased = \"это тестовая 777 строка для proverki результата\"\n",
    "\n",
    "pred, spaced_pred = predict_with_spaces(test_str, model_saved, tokenizer_saved)\n",
    "print(f\"target:  {test_str_spased}\")\n",
    "print(f\"predict: {pred}\")\n",
    "print(f\"target:  {define_spaces(test_str_spased)}\")\n",
    "print(f\"predict: {spaced_pred}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
